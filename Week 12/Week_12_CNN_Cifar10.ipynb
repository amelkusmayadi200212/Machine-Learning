{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "xqfTMsXYhUh5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the CNN architecture\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, kernel_size=3, pooling_type='max'):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.kernel_size = kernel_size\n",
        "        self.pooling_type = pooling_type\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=self.kernel_size, padding=self.kernel_size // 2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=self.kernel_size, padding=self.kernel_size // 2)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=self.kernel_size, padding=self.kernel_size // 2)\n",
        "\n",
        "        if self.pooling_type == 'max':\n",
        "            self.pool = nn.MaxPool2d(2, 2)\n",
        "        elif self.pooling_type == 'avg':\n",
        "            self.pool = nn.AvgPool2d(2, 2)\n",
        "\n",
        "        self.fc1 = nn.Linear(128 * 4 * 4, 256)\n",
        "        self.fc2 = nn.Linear(256, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = self.relu(self.conv3(x))\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = x.view(-1, 128 * 4 * 4)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "qmgyc-jZhaSo"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess CIFAR-10 dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)"
      ],
      "metadata": {
        "id": "J1mKz5C4hdVn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fd51242-92d9-45ee-80b2-3484db25ba4c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Early Stopping Callback\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=10, delta=0):\n",
        "        self.patience = patience\n",
        "        self.delta = delta\n",
        "        self.counter = 0\n",
        "        self.best_loss = None\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, val_loss):\n",
        "        if self.best_loss is None:\n",
        "            self.best_loss = val_loss\n",
        "        elif val_loss > self.best_loss - self.delta:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0"
      ],
      "metadata": {
        "id": "abh7rP5ZhfXK"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and evaluate function\n",
        "def train_and_evaluate(kernel_size, pooling_type, optimizer_type, epochs):\n",
        "    model = CNN(kernel_size=kernel_size, pooling_type=pooling_type).to(device)\n",
        "\n",
        "    # Define optimizer\n",
        "    if optimizer_type == 'SGD':\n",
        "        optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "    elif optimizer_type == 'RMSProp':\n",
        "        optimizer = optim.RMSprop(model.parameters(), lr=0.001)\n",
        "    elif optimizer_type == 'Adam':\n",
        "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
        "    early_stopping = EarlyStopping(patience=10)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        val_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in test_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        test_accuracy = 100 * correct / total\n",
        "        scheduler.step(val_loss)\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Training Loss: {running_loss/len(train_loader):.4f}, Validation Loss: {val_loss/len(test_loader):.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n",
        "\n",
        "        if early_stopping(val_loss):\n",
        "            print(\"Early stopping triggered\")\n",
        "            break"
      ],
      "metadata": {
        "id": "Ko6T7Te7hiD1"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters to compare\n",
        "kernel_sizes = [3, 5, 7]\n",
        "pooling_types = ['max', 'avg']\n",
        "optimizers = ['SGD', 'RMSProp', 'Adam']\n",
        "epochs_list = [5]\n",
        "# epochs_list = [5, 50, 100, 250, 350]\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Iterate through configurations\n",
        "for kernel_size in kernel_sizes:\n",
        "    for pooling_type in pooling_types:\n",
        "        for optimizer_type in optimizers:\n",
        "            for epochs in epochs_list:\n",
        "                print(f\"\\nConfiguration: Kernel={kernel_size}, Pooling={pooling_type}, Optimizer={optimizer_type}, Epochs={epochs}\")\n",
        "                train_and_evaluate(kernel_size, pooling_type, optimizer_type, epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VxevN-EhwWf",
        "outputId": "be508132-4f05-4f60-df95-9c15e14fa6c0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Configuration: Kernel=3, Pooling=max, Optimizer=SGD, Epochs=5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Training Loss: 2.0568, Validation Loss: 1.7548, Test Accuracy: 36.08%\n",
            "Epoch 2/5, Training Loss: 1.6536, Validation Loss: 1.5139, Test Accuracy: 44.43%\n",
            "Epoch 3/5, Training Loss: 1.4782, Validation Loss: 1.3378, Test Accuracy: 51.95%\n",
            "Epoch 4/5, Training Loss: 1.3522, Validation Loss: 1.2371, Test Accuracy: 54.95%\n",
            "Epoch 5/5, Training Loss: 1.2332, Validation Loss: 1.1193, Test Accuracy: 60.30%\n",
            "\n",
            "Configuration: Kernel=3, Pooling=max, Optimizer=RMSProp, Epochs=5\n",
            "Epoch 1/5, Training Loss: 1.7835, Validation Loss: 1.4865, Test Accuracy: 44.79%\n",
            "Epoch 2/5, Training Loss: 1.4469, Validation Loss: 1.3228, Test Accuracy: 51.82%\n",
            "Epoch 3/5, Training Loss: 1.2758, Validation Loss: 1.1686, Test Accuracy: 57.52%\n",
            "Epoch 4/5, Training Loss: 1.1598, Validation Loss: 1.0657, Test Accuracy: 62.10%\n",
            "Epoch 5/5, Training Loss: 1.0750, Validation Loss: 0.9972, Test Accuracy: 63.46%\n",
            "\n",
            "Configuration: Kernel=3, Pooling=max, Optimizer=Adam, Epochs=5\n",
            "Epoch 1/5, Training Loss: 1.7045, Validation Loss: 1.3894, Test Accuracy: 48.86%\n",
            "Epoch 2/5, Training Loss: 1.3888, Validation Loss: 1.2535, Test Accuracy: 54.90%\n",
            "Epoch 3/5, Training Loss: 1.2203, Validation Loss: 1.0944, Test Accuracy: 61.28%\n",
            "Epoch 4/5, Training Loss: 1.0991, Validation Loss: 0.9859, Test Accuracy: 64.94%\n",
            "Epoch 5/5, Training Loss: 1.0178, Validation Loss: 0.9521, Test Accuracy: 66.22%\n",
            "\n",
            "Configuration: Kernel=3, Pooling=avg, Optimizer=SGD, Epochs=5\n",
            "Epoch 1/5, Training Loss: 2.1588, Validation Loss: 1.9311, Test Accuracy: 30.22%\n",
            "Epoch 2/5, Training Loss: 1.8294, Validation Loss: 1.6720, Test Accuracy: 39.57%\n",
            "Epoch 3/5, Training Loss: 1.6758, Validation Loss: 1.5728, Test Accuracy: 42.70%\n",
            "Epoch 4/5, Training Loss: 1.5630, Validation Loss: 1.4622, Test Accuracy: 47.51%\n",
            "Epoch 5/5, Training Loss: 1.4885, Validation Loss: 1.3900, Test Accuracy: 49.70%\n",
            "\n",
            "Configuration: Kernel=3, Pooling=avg, Optimizer=RMSProp, Epochs=5\n",
            "Epoch 1/5, Training Loss: 1.7852, Validation Loss: 1.5764, Test Accuracy: 42.82%\n",
            "Epoch 2/5, Training Loss: 1.4942, Validation Loss: 1.4146, Test Accuracy: 49.51%\n",
            "Epoch 3/5, Training Loss: 1.3812, Validation Loss: 1.2631, Test Accuracy: 54.12%\n",
            "Epoch 4/5, Training Loss: 1.2883, Validation Loss: 1.2885, Test Accuracy: 54.12%\n",
            "Epoch 5/5, Training Loss: 1.2083, Validation Loss: 1.1001, Test Accuracy: 60.32%\n",
            "\n",
            "Configuration: Kernel=3, Pooling=avg, Optimizer=Adam, Epochs=5\n",
            "Epoch 1/5, Training Loss: 1.7532, Validation Loss: 1.4696, Test Accuracy: 46.74%\n",
            "Epoch 2/5, Training Loss: 1.4818, Validation Loss: 1.3474, Test Accuracy: 50.84%\n",
            "Epoch 3/5, Training Loss: 1.3699, Validation Loss: 1.2543, Test Accuracy: 54.58%\n",
            "Epoch 4/5, Training Loss: 1.2713, Validation Loss: 1.1570, Test Accuracy: 57.98%\n",
            "Epoch 5/5, Training Loss: 1.1878, Validation Loss: 1.0655, Test Accuracy: 61.45%\n",
            "\n",
            "Configuration: Kernel=5, Pooling=max, Optimizer=SGD, Epochs=5\n",
            "Epoch 1/5, Training Loss: 1.9676, Validation Loss: 1.6910, Test Accuracy: 38.79%\n",
            "Epoch 2/5, Training Loss: 1.5686, Validation Loss: 1.4122, Test Accuracy: 48.60%\n",
            "Epoch 3/5, Training Loss: 1.3815, Validation Loss: 1.2648, Test Accuracy: 54.39%\n",
            "Epoch 4/5, Training Loss: 1.2191, Validation Loss: 1.1113, Test Accuracy: 60.02%\n",
            "Epoch 5/5, Training Loss: 1.1032, Validation Loss: 1.0317, Test Accuracy: 62.84%\n",
            "\n",
            "Configuration: Kernel=5, Pooling=max, Optimizer=RMSProp, Epochs=5\n",
            "Epoch 1/5, Training Loss: 1.8890, Validation Loss: 1.5213, Test Accuracy: 43.06%\n",
            "Epoch 2/5, Training Loss: 1.4629, Validation Loss: 1.2835, Test Accuracy: 53.98%\n",
            "Epoch 3/5, Training Loss: 1.2890, Validation Loss: 1.1676, Test Accuracy: 58.08%\n",
            "Epoch 4/5, Training Loss: 1.1723, Validation Loss: 1.0669, Test Accuracy: 62.21%\n",
            "Epoch 5/5, Training Loss: 1.0872, Validation Loss: 0.9939, Test Accuracy: 64.96%\n",
            "\n",
            "Configuration: Kernel=5, Pooling=max, Optimizer=Adam, Epochs=5\n",
            "Epoch 1/5, Training Loss: 1.7101, Validation Loss: 1.3953, Test Accuracy: 49.17%\n",
            "Epoch 2/5, Training Loss: 1.3332, Validation Loss: 1.1425, Test Accuracy: 59.62%\n",
            "Epoch 3/5, Training Loss: 1.1482, Validation Loss: 1.0336, Test Accuracy: 63.76%\n",
            "Epoch 4/5, Training Loss: 1.0185, Validation Loss: 0.9440, Test Accuracy: 66.92%\n",
            "Epoch 5/5, Training Loss: 0.9368, Validation Loss: 0.8928, Test Accuracy: 68.58%\n",
            "\n",
            "Configuration: Kernel=5, Pooling=avg, Optimizer=SGD, Epochs=5\n",
            "Epoch 1/5, Training Loss: 2.0873, Validation Loss: 1.8223, Test Accuracy: 33.26%\n",
            "Epoch 2/5, Training Loss: 1.7461, Validation Loss: 1.5860, Test Accuracy: 42.37%\n",
            "Epoch 3/5, Training Loss: 1.5690, Validation Loss: 1.4595, Test Accuracy: 46.42%\n",
            "Epoch 4/5, Training Loss: 1.4699, Validation Loss: 1.3824, Test Accuracy: 49.04%\n",
            "Epoch 5/5, Training Loss: 1.3869, Validation Loss: 1.2937, Test Accuracy: 53.47%\n",
            "\n",
            "Configuration: Kernel=5, Pooling=avg, Optimizer=RMSProp, Epochs=5\n",
            "Epoch 1/5, Training Loss: 1.9222, Validation Loss: 1.6310, Test Accuracy: 40.60%\n",
            "Epoch 2/5, Training Loss: 1.5751, Validation Loss: 1.5252, Test Accuracy: 43.99%\n",
            "Epoch 3/5, Training Loss: 1.4370, Validation Loss: 1.3495, Test Accuracy: 50.85%\n",
            "Epoch 4/5, Training Loss: 1.3162, Validation Loss: 1.2014, Test Accuracy: 56.51%\n",
            "Epoch 5/5, Training Loss: 1.2198, Validation Loss: 1.1547, Test Accuracy: 59.38%\n",
            "\n",
            "Configuration: Kernel=5, Pooling=avg, Optimizer=Adam, Epochs=5\n",
            "Epoch 1/5, Training Loss: 1.7315, Validation Loss: 1.4585, Test Accuracy: 46.17%\n",
            "Epoch 2/5, Training Loss: 1.4089, Validation Loss: 1.2704, Test Accuracy: 54.26%\n",
            "Epoch 3/5, Training Loss: 1.2351, Validation Loss: 1.1378, Test Accuracy: 58.91%\n",
            "Epoch 4/5, Training Loss: 1.1121, Validation Loss: 1.0103, Test Accuracy: 63.67%\n",
            "Epoch 5/5, Training Loss: 1.0256, Validation Loss: 0.9786, Test Accuracy: 65.79%\n",
            "\n",
            "Configuration: Kernel=7, Pooling=max, Optimizer=SGD, Epochs=5\n",
            "Epoch 1/5, Training Loss: 1.9325, Validation Loss: 1.6543, Test Accuracy: 38.98%\n",
            "Epoch 2/5, Training Loss: 1.5441, Validation Loss: 1.3813, Test Accuracy: 49.59%\n",
            "Epoch 3/5, Training Loss: 1.3327, Validation Loss: 1.1852, Test Accuracy: 56.44%\n",
            "Epoch 4/5, Training Loss: 1.1852, Validation Loss: 1.1156, Test Accuracy: 59.94%\n",
            "Epoch 5/5, Training Loss: 1.0694, Validation Loss: 1.0190, Test Accuracy: 63.70%\n",
            "\n",
            "Configuration: Kernel=7, Pooling=max, Optimizer=RMSProp, Epochs=5\n",
            "Epoch 1/5, Training Loss: 2.3208, Validation Loss: 1.6470, Test Accuracy: 39.89%\n",
            "Epoch 2/5, Training Loss: 1.6340, Validation Loss: 1.4989, Test Accuracy: 45.20%\n",
            "Epoch 3/5, Training Loss: 1.4646, Validation Loss: 1.3579, Test Accuracy: 51.43%\n",
            "Epoch 4/5, Training Loss: 1.3349, Validation Loss: 1.2873, Test Accuracy: 52.61%\n",
            "Epoch 5/5, Training Loss: 1.2342, Validation Loss: 1.2287, Test Accuracy: 56.85%\n",
            "\n",
            "Configuration: Kernel=7, Pooling=max, Optimizer=Adam, Epochs=5\n",
            "Epoch 1/5, Training Loss: 1.6975, Validation Loss: 1.4115, Test Accuracy: 48.16%\n",
            "Epoch 2/5, Training Loss: 1.3319, Validation Loss: 1.1891, Test Accuracy: 57.11%\n",
            "Epoch 3/5, Training Loss: 1.1489, Validation Loss: 1.0542, Test Accuracy: 62.37%\n",
            "Epoch 4/5, Training Loss: 1.0391, Validation Loss: 0.9645, Test Accuracy: 66.19%\n",
            "Epoch 5/5, Training Loss: 0.9620, Validation Loss: 0.9278, Test Accuracy: 67.72%\n",
            "\n",
            "Configuration: Kernel=7, Pooling=avg, Optimizer=SGD, Epochs=5\n",
            "Epoch 1/5, Training Loss: 2.0517, Validation Loss: 1.7929, Test Accuracy: 33.63%\n",
            "Epoch 2/5, Training Loss: 1.7046, Validation Loss: 1.5690, Test Accuracy: 42.82%\n",
            "Epoch 3/5, Training Loss: 1.5535, Validation Loss: 1.4521, Test Accuracy: 46.91%\n",
            "Epoch 4/5, Training Loss: 1.4466, Validation Loss: 1.3374, Test Accuracy: 51.15%\n",
            "Epoch 5/5, Training Loss: 1.3496, Validation Loss: 1.2762, Test Accuracy: 53.50%\n",
            "\n",
            "Configuration: Kernel=7, Pooling=avg, Optimizer=RMSProp, Epochs=5\n",
            "Epoch 1/5, Training Loss: 2.0414, Validation Loss: 1.7799, Test Accuracy: 35.54%\n",
            "Epoch 2/5, Training Loss: 1.6006, Validation Loss: 1.4343, Test Accuracy: 47.59%\n",
            "Epoch 3/5, Training Loss: 1.4463, Validation Loss: 1.3541, Test Accuracy: 50.54%\n",
            "Epoch 4/5, Training Loss: 1.3316, Validation Loss: 1.2380, Test Accuracy: 55.63%\n",
            "Epoch 5/5, Training Loss: 1.2288, Validation Loss: 1.1396, Test Accuracy: 59.21%\n",
            "\n",
            "Configuration: Kernel=7, Pooling=avg, Optimizer=Adam, Epochs=5\n",
            "Epoch 1/5, Training Loss: 1.7508, Validation Loss: 1.5133, Test Accuracy: 44.89%\n",
            "Epoch 2/5, Training Loss: 1.4315, Validation Loss: 1.3152, Test Accuracy: 51.88%\n",
            "Epoch 3/5, Training Loss: 1.2819, Validation Loss: 1.1570, Test Accuracy: 58.14%\n",
            "Epoch 4/5, Training Loss: 1.1577, Validation Loss: 1.0714, Test Accuracy: 62.32%\n",
            "Epoch 5/5, Training Loss: 1.0654, Validation Loss: 0.9828, Test Accuracy: 65.51%\n"
          ]
        }
      ]
    }
  ]
}