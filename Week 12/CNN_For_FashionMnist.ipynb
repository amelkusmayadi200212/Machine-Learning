{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MSoL7iqRTruF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the CNN architecture\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, kernel_size=3, pooling_type='max'):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.kernel_size = kernel_size\n",
        "        self.pooling_type = pooling_type\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=self.kernel_size, padding=self.kernel_size // 2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=self.kernel_size, padding=self.kernel_size // 2)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=self.kernel_size, padding=self.kernel_size // 2)\n",
        "\n",
        "        if self.pooling_type == 'max':\n",
        "            self.pool = nn.MaxPool2d(2, 2)\n",
        "        elif self.pooling_type == 'avg':\n",
        "            self.pool = nn.AvgPool2d(2, 2)\n",
        "\n",
        "        self.fc1 = nn.Linear(128 * 3 * 3, 256)\n",
        "        self.fc2 = nn.Linear(256, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = self.relu(self.conv3(x))\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = x.view(-1, 128 * 3 * 3)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "FO5dLrfvUCBp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess FashionMNIST dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)"
      ],
      "metadata": {
        "id": "tcdQAYwZUD80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f00b4a97-5444-40ec-d113-c50cd7241f8c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:00<00:00, 116MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 5.95MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.42M/4.42M [00:00<00:00, 68.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 26.0MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Early Stopping Callback\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=10, delta=0):\n",
        "        self.patience = patience\n",
        "        self.delta = delta\n",
        "        self.counter = 0\n",
        "        self.best_loss = None\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, val_loss):\n",
        "        if self.best_loss is None:\n",
        "            self.best_loss = val_loss\n",
        "        elif val_loss > self.best_loss - self.delta:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0"
      ],
      "metadata": {
        "id": "p-2DDbRHUH6N"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and evaluate function\n",
        "def train_and_evaluate(kernel_size, pooling_type, optimizer_type, epochs):\n",
        "    model = CNN(kernel_size=kernel_size, pooling_type=pooling_type).to(device)\n",
        "\n",
        "    # Define optimizer\n",
        "    if optimizer_type == 'SGD':\n",
        "        optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "    elif optimizer_type == 'RMSProp':\n",
        "        optimizer = optim.RMSprop(model.parameters(), lr=0.001)\n",
        "    elif optimizer_type == 'Adam':\n",
        "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
        "    early_stopping = EarlyStopping(patience=10)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        val_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in test_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        test_accuracy = 100 * correct / total\n",
        "        scheduler.step(val_loss)\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Training Loss: {running_loss/len(train_loader):.4f}, Validation Loss: {val_loss/len(test_loader):.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n",
        "\n",
        "        if early_stopping(val_loss):\n",
        "            print(\"Early stopping triggered\")\n",
        "            break"
      ],
      "metadata": {
        "id": "ScdMdc3qUHwS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters to compare\n",
        "kernel_sizes = [3, 5, 7]\n",
        "pooling_types = ['max', 'avg']\n",
        "optimizers = ['SGD', 'RMSProp', 'Adam']\n",
        "epochs_list = [5]\n",
        "# epochs_list = [5, 50, 100, 250, 350]\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Iterate through configurations\n",
        "for kernel_size in kernel_sizes:\n",
        "    for pooling_type in pooling_types:\n",
        "        for optimizer_type in optimizers:\n",
        "            for epochs in epochs_list:\n",
        "                print(f\"\\nConfiguration: Kernel={kernel_size}, Pooling={pooling_type}, Optimizer={optimizer_type}, Epochs={epochs}\")\n",
        "                train_and_evaluate(kernel_size, pooling_type, optimizer_type, epochs)"
      ],
      "metadata": {
        "id": "9w7UTiZ1UHli",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8647dfec-c158-4ad0-d667-a17c7c9df414"
      },
      "execution_count": 6,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Configuration: Kernel=3, Pooling=max, Optimizer=SGD, Epochs=5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Training Loss: 0.9744, Validation Loss: 0.5605, Test Accuracy: 78.13%\n",
            "Epoch 2/5, Training Loss: 0.5207, Validation Loss: 0.4577, Test Accuracy: 82.62%\n",
            "Epoch 3/5, Training Loss: 0.4291, Validation Loss: 0.3894, Test Accuracy: 85.20%\n",
            "Epoch 4/5, Training Loss: 0.3786, Validation Loss: 0.3433, Test Accuracy: 86.99%\n",
            "Epoch 5/5, Training Loss: 0.3430, Validation Loss: 0.3416, Test Accuracy: 87.67%\n",
            "\n",
            "Configuration: Kernel=3, Pooling=max, Optimizer=RMSProp, Epochs=5\n",
            "Epoch 1/5, Training Loss: 0.7429, Validation Loss: 0.4614, Test Accuracy: 82.84%\n",
            "Epoch 2/5, Training Loss: 0.4177, Validation Loss: 0.3546, Test Accuracy: 86.87%\n",
            "Epoch 3/5, Training Loss: 0.3472, Validation Loss: 0.3130, Test Accuracy: 88.57%\n",
            "Epoch 4/5, Training Loss: 0.3021, Validation Loss: 0.2965, Test Accuracy: 88.91%\n",
            "Epoch 5/5, Training Loss: 0.2746, Validation Loss: 0.2757, Test Accuracy: 89.87%\n",
            "\n",
            "Configuration: Kernel=3, Pooling=max, Optimizer=Adam, Epochs=5\n",
            "Epoch 1/5, Training Loss: 0.6083, Validation Loss: 0.3772, Test Accuracy: 86.03%\n",
            "Epoch 2/5, Training Loss: 0.3601, Validation Loss: 0.3196, Test Accuracy: 88.10%\n",
            "Epoch 3/5, Training Loss: 0.3103, Validation Loss: 0.2824, Test Accuracy: 89.43%\n",
            "Epoch 4/5, Training Loss: 0.2769, Validation Loss: 0.2766, Test Accuracy: 90.06%\n",
            "Epoch 5/5, Training Loss: 0.2559, Validation Loss: 0.2550, Test Accuracy: 90.91%\n",
            "\n",
            "Configuration: Kernel=3, Pooling=avg, Optimizer=SGD, Epochs=5\n",
            "Epoch 1/5, Training Loss: 1.1308, Validation Loss: 0.6825, Test Accuracy: 73.66%\n",
            "Epoch 2/5, Training Loss: 0.6828, Validation Loss: 0.5832, Test Accuracy: 77.30%\n",
            "Epoch 3/5, Training Loss: 0.5880, Validation Loss: 0.5332, Test Accuracy: 79.64%\n",
            "Epoch 4/5, Training Loss: 0.5299, Validation Loss: 0.4893, Test Accuracy: 81.44%\n",
            "Epoch 5/5, Training Loss: 0.4930, Validation Loss: 0.4511, Test Accuracy: 82.90%\n",
            "\n",
            "Configuration: Kernel=3, Pooling=avg, Optimizer=RMSProp, Epochs=5\n",
            "Epoch 1/5, Training Loss: 0.7447, Validation Loss: 0.5253, Test Accuracy: 80.08%\n",
            "Epoch 2/5, Training Loss: 0.4777, Validation Loss: 0.3936, Test Accuracy: 85.41%\n",
            "Epoch 3/5, Training Loss: 0.3931, Validation Loss: 0.3473, Test Accuracy: 87.09%\n",
            "Epoch 4/5, Training Loss: 0.3480, Validation Loss: 0.3273, Test Accuracy: 88.21%\n",
            "Epoch 5/5, Training Loss: 0.3186, Validation Loss: 0.3221, Test Accuracy: 88.28%\n",
            "\n",
            "Configuration: Kernel=3, Pooling=avg, Optimizer=Adam, Epochs=5\n",
            "Epoch 1/5, Training Loss: 0.7263, Validation Loss: 0.4968, Test Accuracy: 80.75%\n",
            "Epoch 2/5, Training Loss: 0.4784, Validation Loss: 0.4002, Test Accuracy: 85.52%\n",
            "Epoch 3/5, Training Loss: 0.3981, Validation Loss: 0.3523, Test Accuracy: 87.03%\n",
            "Epoch 4/5, Training Loss: 0.3514, Validation Loss: 0.3226, Test Accuracy: 88.19%\n",
            "Epoch 5/5, Training Loss: 0.3230, Validation Loss: 0.2995, Test Accuracy: 89.18%\n",
            "\n",
            "Configuration: Kernel=5, Pooling=max, Optimizer=SGD, Epochs=5\n",
            "Epoch 1/5, Training Loss: 0.8651, Validation Loss: 0.4981, Test Accuracy: 81.45%\n",
            "Epoch 2/5, Training Loss: 0.4770, Validation Loss: 0.4162, Test Accuracy: 84.58%\n",
            "Epoch 3/5, Training Loss: 0.3942, Validation Loss: 0.3593, Test Accuracy: 86.77%\n",
            "Epoch 4/5, Training Loss: 0.3496, Validation Loss: 0.3313, Test Accuracy: 87.64%\n",
            "Epoch 5/5, Training Loss: 0.3186, Validation Loss: 0.3183, Test Accuracy: 88.02%\n",
            "\n",
            "Configuration: Kernel=5, Pooling=max, Optimizer=RMSProp, Epochs=5\n",
            "Epoch 1/5, Training Loss: 0.6721, Validation Loss: 0.4467, Test Accuracy: 83.48%\n",
            "Epoch 2/5, Training Loss: 0.3807, Validation Loss: 0.3393, Test Accuracy: 87.39%\n",
            "Epoch 3/5, Training Loss: 0.3183, Validation Loss: 0.3053, Test Accuracy: 88.80%\n",
            "Epoch 4/5, Training Loss: 0.2808, Validation Loss: 0.2715, Test Accuracy: 89.83%\n",
            "Epoch 5/5, Training Loss: 0.2553, Validation Loss: 0.2721, Test Accuracy: 89.80%\n",
            "\n",
            "Configuration: Kernel=5, Pooling=max, Optimizer=Adam, Epochs=5\n",
            "Epoch 1/5, Training Loss: 0.5759, Validation Loss: 0.3744, Test Accuracy: 86.26%\n",
            "Epoch 2/5, Training Loss: 0.3505, Validation Loss: 0.3024, Test Accuracy: 88.90%\n",
            "Epoch 3/5, Training Loss: 0.2935, Validation Loss: 0.2898, Test Accuracy: 89.17%\n",
            "Epoch 4/5, Training Loss: 0.2582, Validation Loss: 0.2709, Test Accuracy: 90.03%\n",
            "Epoch 5/5, Training Loss: 0.2358, Validation Loss: 0.2718, Test Accuracy: 90.23%\n",
            "\n",
            "Configuration: Kernel=5, Pooling=avg, Optimizer=SGD, Epochs=5\n",
            "Epoch 1/5, Training Loss: 1.0974, Validation Loss: 0.6578, Test Accuracy: 73.91%\n",
            "Epoch 2/5, Training Loss: 0.6170, Validation Loss: 0.5401, Test Accuracy: 79.27%\n",
            "Epoch 3/5, Training Loss: 0.5362, Validation Loss: 0.4865, Test Accuracy: 81.59%\n",
            "Epoch 4/5, Training Loss: 0.4822, Validation Loss: 0.4528, Test Accuracy: 82.49%\n",
            "Epoch 5/5, Training Loss: 0.4470, Validation Loss: 0.4092, Test Accuracy: 84.41%\n",
            "\n",
            "Configuration: Kernel=5, Pooling=avg, Optimizer=RMSProp, Epochs=5\n",
            "Epoch 1/5, Training Loss: 0.7508, Validation Loss: 0.4847, Test Accuracy: 81.50%\n",
            "Epoch 2/5, Training Loss: 0.4583, Validation Loss: 0.3886, Test Accuracy: 85.98%\n",
            "Epoch 3/5, Training Loss: 0.3800, Validation Loss: 0.3918, Test Accuracy: 85.19%\n",
            "Epoch 4/5, Training Loss: 0.3380, Validation Loss: 0.3237, Test Accuracy: 88.10%\n",
            "Epoch 5/5, Training Loss: 0.3097, Validation Loss: 0.3045, Test Accuracy: 88.66%\n",
            "\n",
            "Configuration: Kernel=5, Pooling=avg, Optimizer=Adam, Epochs=5\n",
            "Epoch 1/5, Training Loss: 0.6942, Validation Loss: 0.5089, Test Accuracy: 80.78%\n",
            "Epoch 2/5, Training Loss: 0.4426, Validation Loss: 0.3878, Test Accuracy: 85.41%\n",
            "Epoch 3/5, Training Loss: 0.3614, Validation Loss: 0.3267, Test Accuracy: 87.77%\n",
            "Epoch 4/5, Training Loss: 0.3233, Validation Loss: 0.3089, Test Accuracy: 88.54%\n",
            "Epoch 5/5, Training Loss: 0.2940, Validation Loss: 0.3135, Test Accuracy: 88.24%\n",
            "\n",
            "Configuration: Kernel=7, Pooling=max, Optimizer=SGD, Epochs=5\n",
            "Epoch 1/5, Training Loss: 0.8276, Validation Loss: 0.4967, Test Accuracy: 81.37%\n",
            "Epoch 2/5, Training Loss: 0.4519, Validation Loss: 0.3891, Test Accuracy: 85.70%\n",
            "Epoch 3/5, Training Loss: 0.3747, Validation Loss: 0.3493, Test Accuracy: 86.91%\n",
            "Epoch 4/5, Training Loss: 0.3296, Validation Loss: 0.3387, Test Accuracy: 87.16%\n",
            "Epoch 5/5, Training Loss: 0.3007, Validation Loss: 0.3049, Test Accuracy: 88.98%\n",
            "\n",
            "Configuration: Kernel=7, Pooling=max, Optimizer=RMSProp, Epochs=5\n",
            "Epoch 1/5, Training Loss: 0.8108, Validation Loss: 0.4500, Test Accuracy: 83.54%\n",
            "Epoch 2/5, Training Loss: 0.4206, Validation Loss: 0.3859, Test Accuracy: 86.07%\n",
            "Epoch 3/5, Training Loss: 0.3510, Validation Loss: 0.3454, Test Accuracy: 87.28%\n",
            "Epoch 4/5, Training Loss: 0.3094, Validation Loss: 0.3071, Test Accuracy: 88.90%\n",
            "Epoch 5/5, Training Loss: 0.2844, Validation Loss: 0.2935, Test Accuracy: 89.46%\n",
            "\n",
            "Configuration: Kernel=7, Pooling=max, Optimizer=Adam, Epochs=5\n",
            "Epoch 1/5, Training Loss: 0.5754, Validation Loss: 0.3681, Test Accuracy: 86.54%\n",
            "Epoch 2/5, Training Loss: 0.3412, Validation Loss: 0.3122, Test Accuracy: 88.22%\n",
            "Epoch 3/5, Training Loss: 0.2876, Validation Loss: 0.2688, Test Accuracy: 90.01%\n",
            "Epoch 4/5, Training Loss: 0.2594, Validation Loss: 0.2795, Test Accuracy: 89.80%\n",
            "Epoch 5/5, Training Loss: 0.2366, Validation Loss: 0.2741, Test Accuracy: 90.63%\n",
            "\n",
            "Configuration: Kernel=7, Pooling=avg, Optimizer=SGD, Epochs=5\n",
            "Epoch 1/5, Training Loss: 1.0768, Validation Loss: 0.6571, Test Accuracy: 74.56%\n",
            "Epoch 2/5, Training Loss: 0.5898, Validation Loss: 0.5230, Test Accuracy: 79.87%\n",
            "Epoch 3/5, Training Loss: 0.5083, Validation Loss: 0.4677, Test Accuracy: 82.38%\n",
            "Epoch 4/5, Training Loss: 0.4593, Validation Loss: 0.4322, Test Accuracy: 83.85%\n",
            "Epoch 5/5, Training Loss: 0.4138, Validation Loss: 0.4008, Test Accuracy: 84.95%\n",
            "\n",
            "Configuration: Kernel=7, Pooling=avg, Optimizer=RMSProp, Epochs=5\n",
            "Epoch 1/5, Training Loss: 0.8658, Validation Loss: 0.5536, Test Accuracy: 78.76%\n",
            "Epoch 2/5, Training Loss: 0.4876, Validation Loss: 0.4342, Test Accuracy: 83.06%\n",
            "Epoch 3/5, Training Loss: 0.3889, Validation Loss: 0.3707, Test Accuracy: 85.98%\n",
            "Epoch 4/5, Training Loss: 0.3367, Validation Loss: 0.3294, Test Accuracy: 87.64%\n",
            "Epoch 5/5, Training Loss: 0.3044, Validation Loss: 0.3147, Test Accuracy: 88.33%\n",
            "\n",
            "Configuration: Kernel=7, Pooling=avg, Optimizer=Adam, Epochs=5\n",
            "Epoch 1/5, Training Loss: 0.6838, Validation Loss: 0.4618, Test Accuracy: 82.48%\n",
            "Epoch 2/5, Training Loss: 0.4244, Validation Loss: 0.3812, Test Accuracy: 86.15%\n",
            "Epoch 3/5, Training Loss: 0.3539, Validation Loss: 0.3478, Test Accuracy: 87.16%\n",
            "Epoch 4/5, Training Loss: 0.3112, Validation Loss: 0.3089, Test Accuracy: 88.55%\n",
            "Epoch 5/5, Training Loss: 0.2835, Validation Loss: 0.3057, Test Accuracy: 88.71%\n"
          ]
        }
      ]
    }
  ]
}